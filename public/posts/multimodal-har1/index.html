<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="color-scheme" content="light dark">

    
      <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self'; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self'; img-src 'self'; object-src 'none'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/; script-src 'self' 'unsafe-inline' https://www.google-analytics.com https://cdn.jsdelivr.net/; prefetch-src 'self'; connect-src 'self' https://www.google-analytics.com;">

    

    <meta name="author" content="Muhammad Bilal Shaikh">
    <meta name="description" content="In this I will follow my preffered briefing method the WHAC method.
What?    Compressed video formats produced different modalities which includes i-frames, p-frames, b-frames and audio. A recent beautiful work from CVPR 2022, produced four transformer-based architectures to fuse these four modalities in an interesting way.
Using the base Vit and ViViT models, MM-ViT scored better or equally nearby scores on UCF101, Kinetics 600 and SomethingSomethingv2 (without audio dataset).">
    <meta name="keywords" content="blog,developer,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Multimodal Action recognition in Compressed Video"/>
<meta name="twitter:description" content="In this I will follow my preffered briefing method the WHAC method.
What?    Compressed video formats produced different modalities which includes i-frames, p-frames, b-frames and audio. A recent beautiful work from CVPR 2022, produced four transformer-based architectures to fuse these four modalities in an interesting way.
Using the base Vit and ViViT models, MM-ViT scored better or equally nearby scores on UCF101, Kinetics 600 and SomethingSomethingv2 (without audio dataset)."/>

    <meta property="og:title" content="Multimodal Action recognition in Compressed Video" />
<meta property="og:description" content="In this I will follow my preffered briefing method the WHAC method.
What?    Compressed video formats produced different modalities which includes i-frames, p-frames, b-frames and audio. A recent beautiful work from CVPR 2022, produced four transformer-based architectures to fuse these four modalities in an interesting way.
Using the base Vit and ViViT models, MM-ViT scored better or equally nearby scores on UCF101, Kinetics 600 and SomethingSomethingv2 (without audio dataset)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/multimodal-har1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-30T19:34:52+08:00" />
<meta property="article:modified_time" content="2022-05-30T19:34:52+08:00" />



    <title>
  Multimodal Action recognition in Compressed Video · MBS
</title>

    
      <link rel="canonical" href="/posts/multimodal-har1/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css" integrity="sha256-2f3b/&#43;byfmmYXcX&#43;BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.002ee2378e14c7a68f1f0a53d9694ed252090987c4e768023fac694a4fc5f793.css" integrity="sha256-AC7iN44Ux6aPHwpT2WlO0lIJCYfE52gCP6xpSk/F95M=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <meta name="generator" content="Hugo 0.99.1" />
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto">
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      MBS
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/projects/">Projects</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/contact/">Contact me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="/posts/multimodal-har1/">
              Multimodal Action recognition in Compressed Video
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-05-30T19:34:52&#43;08:00">
                May 30, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              2-minute read
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/mbs/">MBS</a></div>

          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/multimodal/">multimodal</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/computer-vision/">computer vision</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <p>In this I will follow my preffered briefing method the <strong>WHAC</strong> method.</p>
<h2 id="what">
  What?
  <a class="heading-link" href="#what">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>Compressed video formats produced different modalities which includes i-frames, p-frames, b-frames and audio. A recent <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Chen_MM-ViT_Multi-Modal_Video_Transformer_for_Compressed_Video_Action_Recognition_WACV_2022_paper.pdf">beautiful work</a> from <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>, produced <a href="#four">four</a>  transformer-based architectures to fuse these four modalities in an interesting way.</p>
<p>Using the base <a href="#">Vit</a> and <a href="#">ViViT</a> models, MM-ViT scored better or equally nearby scores on UCF101, Kinetics 600 and SomethingSomethingv2 (without audio dataset).</p>
<p>This approach has mapped each modality into a representation compatible with transformer architecture which expects a parallel input in the form of patches/tokens.</p>
<p><img src="/img/overall.png" alt="overall architecture"></p>
<p>This work has different interesting parts.</p>
<h2 id="how">
  How?
  <a class="heading-link" href="#how">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>MM-ViT converts non-audio modalities in a different way as compared to audio modality. Basically, waveform has been used for audio representation. Transformer-based abstract variables (query, key, value) were extracted for each modality and are passed through an MLP to the attention mechanism. As mentioned four, there are four different architectures named different on the basis of key module they use.</p>
<p><img src="/img/mechanisms.png" alt="overall architecture"></p>
<h2 id="are-we-sure">
  Are we sure?
  <a class="heading-link" href="#are-we-sure">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>MM-ViT III is the best variant produced which has beaten SOTA CNN variants with and without optical flow. MM-ViT is efficient as it does not perform the heavy duty for optical flow. For qualitive view of the work picture generated from attention weights have been shared in the manuscript.</p>
<p><img src="/img/ssv2-sota.png" alt="ssv2">
<img src="/img/ucf-101-sota.png" alt="ucf-101">
<img src="/img/kinetics-sota.png" alt="kinetics-600"></p>
<h2 id="can-i-do-it">
  Can I do it?
  <a class="heading-link" href="#can-i-do-it">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>Key candidates for implementation are</p>
<ul>
<li><a href="https://github.com/chaoyuaw/pytorch-coviar">PyTorch for Compressed Video Action Recognition</a></li>
<li><a href="https://github.com/haim-barad/action-recognition-compressed-domain">Accelerating Compressed VAR</a></li>
</ul>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "@mohammadbilalshaikh" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    ©
    
    2022
     Muhammad Bilal Shaikh 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

    </main>

    
      
      <script src="/js/coder.min.8fb86376a16e684af472a329aef502dbebcfab65ce264e9750d144912947c602.js" integrity="sha256-j7hjdqFuaEr0cqMprvUC2&#43;vPq2XOJk6XUNFEkSlHxgI="></script>
    

    

    

    

    

    

    

    

    
  </body>

</html>
